# ğŸš€ Distributed ML Training Platform
#
## ğŸ§‘â€ğŸ’» Tech Stack

- **Frontend:** Next.js (React, TypeScript), Material UI (Google UI components library)
- **Backend:** FastAPI (Python)
- **ML:** scikit-learn
- **Queue/Cache:** Redis
- **Orchestration:** Docker, Docker Compose
- **Other:** CORS Middleware, tqdm, etc.




Welcome to the **Distributed ML Training Platform**! ğŸ‰

Train, tune, and scale your machine learning models with ease using Python, scikit-learn, Redis, and Docker. Submit jobs, watch your workers hustle, and get results fast!


## âœ¨ Features



- ğŸ—‚ï¸ Distributed job queue with Redis
- ğŸ¤– Modular model training (Logistic Regression, Random Forest, etc.)
- ğŸ” Hyperparameter tuning with GridSearchCV
- ğŸ“Š Support for multiple datasets (Iris, Wine, Breast Cancer, Digits)
- ğŸ† Performance metrics: accuracy, precision, recall, F1 score
- ğŸ§© Extensible for new models and datasets
- ğŸ³ Docker-based deployment for scalable distributed training



---

## ğŸ› ï¸ Usage



### ğŸ–¥ï¸ Local Development
1. **Create and activate a virtual environment (recommended):**
	```bash
	python3 -m venv venv
	source venv/bin/activate
	```
2. **Install dependencies:**
	```bash
	pip install -r requirements.txt
	```
3. **Start Redis server** (if not running):
	```bash
	redis-server
	```

### ğŸŒ Frontend (Next.js)

1. **Install frontend dependencies:**
	```bash
	cd frontend
	npm install
	```
2. **Start the frontend development server:**
	```bash
	npm run dev
	# App runs at http://localhost:3000
	```
3. **Frontend features:**
	- Dynamic model/solver/hyperparameter selection
	- Form submission to FastAPI backend
	- Real-time job status and results (if implemented)

### Backend (Redis, Docker)
	```bash
	docker compose up --build --scale worker=3
 	```

### ğŸ”— API Integration

**Submit jobs from frontend:**
Frontend sends POST requests to FastAPI backend (default: http://localhost:8000/create-job)

Example fetch usage:
```js
await fetch('http://localhost:8000/create-job', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
	 type: model,
	 description: dataset,
	 parameters: enabled ? hyperparams : undefined
  })
});
```

**CORS Note:**
Make sure FastAPI backend has CORS enabled:
```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(
	 CORSMiddleware,
	 allow_origins=["http://localhost:3000"],
	 allow_credentials=True,
	 allow_methods=["*"],
	 allow_headers=["*"],
)
```


### ğŸ³ Distributed/Docker Deployment

---

## ğŸ“ Operational Notes & Useful Commands

**Delete all job keys from Docker Redis instance:**
```sh
docker exec distributed-ml-training-platform-redis-1 redis-cli DEL $(docker exec distributed-ml-training-platform-redis-1 redis-cli KEYS 'job:*')
```

**Delete all keys from Redis database:**
```sh
docker exec distributed-ml-training-platform-redis-1 redis-cli FLUSHDB
```

**Run Redis inside Docker:**
```sh
docker compose up redis
```

**Run Redis inside Docker in Detached Mode:**
```sh
docker compose up -d redis
```

**Run Main (with 3 workers):**
```sh
docker compose up --build --scale worker=3
```

**Example: Clean start for distributed training**
```sh
docker compose up -d redis
docker exec distributed-ml-training-platform-redis-1 redis-cli FLUSHDB
docker compose up --build --scale worker=3
```
---
---

## ğŸˆ Tips & Fun Ideas

- Try scaling up the number of workers for super-fast job crunching! ğŸš¦
- Visualize your training progress with `tqdm` progress bars. ğŸ“ˆ
- Experiment with new models and datasetsâ€”make it your own playground! ğŸ§ª
- Use Docker Desktop to watch your containers hustle in real time. ğŸ‘€

---

## ğŸ’¬ Questions or Feedback?

Open an issue or start a discussionâ€”letâ€™s make ML more fun together! ğŸ˜„
